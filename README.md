# Patch-Depth-Of-Field-For-Hyperspectral-Image-Classification

# Description.
The most widely used method for extracting features from a target pixel in hyperspectral images over the past decade has been to capture a patch centering it as feature representation for that specific pixel. Compared to traditional pixel-wise input, the patch-wise input incorporates the spatial information from the target pixel, and thus alleviates the spatial variability associated with individual pixels in hyperspectral images, which will improve model performance significantly. However, the current treatment of patches is insufficient, constraining the classification performance because: 1) the pixels in a patch are treated equally,  failing to form hierarchical contribution to the central pixel; 2) for the pixels situated at the edges of distinct objects or narrow targets, the patch characteristics closely resemble those of nearby pixels with different types, which may cause misclassification due to the model's weak generalization ability. Aiming to these shortages,  we introduce a common concept from photography,  depth of field,  into hyperspectral image analyzing in this paper, and propose a method called patch depth of field (PDoF). With the merit of simple and foreseeable effects, the method is used to integrate into the existing models on four common dataset. The experimental result shows that it can enhance the model performance of the classical models such as $k$nn and single-layer 2-D CNN as well as some state-of-the-art models (e.g. spectralâ€“spatial feature tokenization transformer, spectral swin transformer network). Through upgrading the model performance and interpretability, our method provides a new thinking for patch-based method of hyperspectral image classification task. 
